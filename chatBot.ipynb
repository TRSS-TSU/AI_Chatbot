{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61eb8235-f221-412d-817d-dfe92c4eb90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading chatBot.ipynb in format ipynb\n",
      "[jupytext] Writing chatBot.py (destination file replaced)\n"
     ]
    }
   ],
   "source": [
    "#!jupytext --to py chatBot.ipynb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0584f63a-e0bb-4a76-a29d-abd1c227eda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cab/opt/anaconda3/envs/chat1/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, pipeline, AutoTokenizer\n",
    "from utils.dataloader import loader\n",
    "from utils.metrics import compute_exact\n",
    "import numpy as np\n",
    "from utils.metrics import compute_exact\n",
    "import pandas as pd\n",
    "import os  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8daf7bfd-c65d-4095-ae03-08c227588678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path, 'r') as file:\n",
    "        context  = file.read().replace('\\n', '')\n",
    "    return context\n",
    "\n",
    "def save_results( question, result, ans1,ans2,ans3, conf):\n",
    "    csv_file = \"result/results.csv\"\n",
    "    if os.path.exists(csv_file):\n",
    "        headers= False\n",
    "    else:\n",
    "        headers= True\n",
    "    \n",
    "    df = pd.DataFrame(list(zip([question], [result], [ans1],[ans2],[ans3], [conf])),\n",
    "               columns =[\"question\", \"prediction\", \"model1_result\",\"model2_result\",\"model3_result\", \"confidence_level\" \n",
    "                        ])\n",
    "    \n",
    "    df.to_csv(csv_file, mode = 'a',encoding='utf-8', index=False, header = headers)\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    if \"?\" not in text:\n",
    "        text = text+\"?\"\n",
    "    \n",
    "    return text\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977c196a-7d6b-4f97-ade7-5957b6335b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants\n",
    "NAMES = [\"models/bert-large-uncased-whole-word-masking-squad2\",\t\n",
    "         \"models/roberta-base-squad2\",\t\n",
    "         \"models/minilm-uncased-squad2\"\n",
    "        ]\n",
    "CONTEXT = read_file(\"data/context/NTLM_context.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145e1481-d38e-4248-8dc0-c5a072254984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model and tokenizer intialization\n",
    "model1 = AutoModelForQuestionAnswering.from_pretrained(NAMES[0])\n",
    "model2 = AutoModelForQuestionAnswering.from_pretrained(NAMES[1])\n",
    "model3 = AutoModelForQuestionAnswering.from_pretrained(NAMES[2])\n",
    "\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(NAMES[0], model_max_length =int(1e30))\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(NAMES[1], model_max_length =int(1e30))\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(NAMES[2], model_max_length =int(1e30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2123f87b-9be9-4cd8-8873-39b98cf6d6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To quit type exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">   Why is NTLM systems vulnerable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relatively simplistic form of password hashing Confidence leve: 30.0%\n",
      "To quit type exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  exit\n"
     ]
    }
   ],
   "source": [
    "#start of loop\n",
    "exit_conditions = (\"exit\")\n",
    "while True:\n",
    "    print(\"To quit type exit\")\n",
    "    question = input(\"> \")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if question in exit_conditions:\n",
    "        break\n",
    "    else:\n",
    "        question = preprocess(question)\n",
    "        tokenizer1.encode(question, truncation = True, padding = True, verbose=False)\n",
    "        tokenizer2.encode(question, truncation = True, padding = True, verbose=False)\n",
    "        tokenizer3.encode(question, truncation = True, padding = True, verbose=False)\n",
    "\n",
    "\n",
    "        #init pipeline\n",
    "        m1 = pipeline(\"question-answering\", model=model1 , tokenizer = tokenizer1)\n",
    "        m2 = pipeline(\"question-answering\", model=model2 , tokenizer = tokenizer2)\n",
    "        m3 = pipeline(\"question-answering\", model=model3 , tokenizer = tokenizer3)\n",
    "\n",
    "        #generating prediction\n",
    "        answer1 = m1({ 'question' : question, 'context' : CONTEXT})\n",
    "        answer2 = m2({ 'question' : question, 'context' : CONTEXT})\n",
    "        answer3 = m3({ 'question' : question, 'context' : CONTEXT})\n",
    "        \n",
    "        ans = [answer1[\"answer\"] ,answer2[\"answer\"],answer3[\"answer\"]]\n",
    "        \n",
    "        \n",
    "        a1 = compute_exact(ans[0], ans[1]) + compute_exact(ans[0], ans[2])\n",
    "        a2 = compute_exact(ans[1], ans[0]) + compute_exact(ans[1], ans[2])\n",
    "        a3 = compute_exact(ans[2], ans[0]) + compute_exact(ans[2], ans[1])\n",
    "        calc = [a1,a2,a3]\n",
    "        \n",
    "        if np.sum(calc) == 0:\n",
    "            result = \"no answer\"\n",
    "        else:\n",
    "            result = ans[calc.index(max(calc))]\n",
    "            confidence = np.mean([answer1[\"score\"],answer2[\"score\"],answer3[\"score\"]])\n",
    "\n",
    "        \n",
    "        print(result + \" Confidence leve: \"+ str(round(confidence,2)*100)+\"%\")\n",
    "        \n",
    "        \n",
    "\n",
    "        save_results(question, result, answer1[\"answer\"] ,answer2[\"answer\"],answer3[\"answer\"], round(confidence,2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f594c-8efd-4ea5-80e1-0bcb2e395649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "317b444dc4c45053d5f75bf7526e259789c834293bf2da0d69fdefc839a5832a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
